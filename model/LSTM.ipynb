{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "5161/5161 - 9s - loss: 0.0992 - 9s/epoch - 2ms/step\n",
            "Epoch 2/5\n",
            "5161/5161 - 9s - loss: 0.0981 - 9s/epoch - 2ms/step\n",
            "Epoch 3/5\n",
            "5161/5161 - 8s - loss: 0.0979 - 8s/epoch - 2ms/step\n",
            "Epoch 4/5\n",
            "5161/5161 - 9s - loss: 0.0978 - 9s/epoch - 2ms/step\n",
            "Epoch 5/5\n",
            "5161/5161 - 9s - loss: 0.0976 - 9s/epoch - 2ms/step\n",
            "1291/1291 [==============================] - 2s 1ms/step\n",
            "MAE: 0.545297017212851\n",
            "MSE: 0.29938760410589244\n",
            "RMSE: 0.547163233510707\n",
            "F1-score: 0.14105916357307757\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"crimelstm.csv\")\n",
        "\n",
        "# Select the relevant columns\n",
        "cols = ['Neighbourhood', 'offence_type', 'reportedmonth', 'reporteddayofweek', 'occurrencehour']\n",
        "data = data[cols]\n",
        "\n",
        "# Encode categorical variables\n",
        "cat_cols = ['Neighbourhood', 'offence_type', 'reportedmonth', 'reporteddayofweek']\n",
        "for col in cat_cols:\n",
        "    encoder = LabelEncoder()\n",
        "    data[col] = encoder.fit_transform(data[col])\n",
        "\n",
        "# Normalize numerical variables\n",
        "num_cols = ['occurrencehour']\n",
        "scaler = MinMaxScaler()\n",
        "data[num_cols] = scaler.fit_transform(data[num_cols])\n",
        "\n",
        "# Encode the target variable\n",
        "encoder = LabelEncoder()\n",
        "data['offence_type'] = encoder.fit_transform(data['offence_type'])\n",
        "\n",
        "# Split the data into input (X) and output (y) variables\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the input data for the LSTM\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(1, X_train.shape[2])))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=2)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Transform the y_test data using the same encoder used for training\n",
        "y_test = encoder.transform(y_test)\n",
        "\n",
        "# Evaluate the model using mean absolute error, mean squared error, and F1-score\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "f1 = f1_score(np.round(y_test), np.round(y_pred), average='weighted')\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"MAE:\", mae)\n",
        "print(\"MSE:\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"F1-score:\", f1)\n",
        "\n",
        "# Save the model\n",
        "model.save(\"crime_lstm_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "If using all scalar values, you must pass an index",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m occurrencehour \u001b[39m=\u001b[39m \u001b[39m15\u001b[39m \u001b[39m# 3 PM\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m# Create a dataframe with the input data\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m input_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame({\n\u001b[0;32m     18\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mNeighbourhood\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mUniversity (79)\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     19\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39moffence_type\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mAssault\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     20\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mreportedmonth\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mDecember\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     21\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mreporteddayofweek\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mFriday\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     22\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39moccurrencehour\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m3\u001b[39;49m\n\u001b[0;32m     23\u001b[0m })\n\u001b[0;32m     25\u001b[0m \u001b[39m# Encode categorical variables\u001b[39;00m\n\u001b[0;32m     26\u001b[0m cat_cols \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mNeighbourhood\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39moffence_type\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mreportedmonth\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mreporteddayofweek\u001b[39m\u001b[39m'\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\Akanksha Mishra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:708\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    702\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    703\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    704\u001b[0m     )\n\u001b[0;32m    706\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    707\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    709\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    710\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m \u001b[39mimport\u001b[39;00m mrecords\n",
            "File \u001b[1;32mc:\\Users\\Akanksha Mishra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    479\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 481\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
            "File \u001b[1;32mc:\\Users\\Akanksha Mishra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    113\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    116\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
            "File \u001b[1;32mc:\\Users\\Akanksha Mishra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:645\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    644\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m indexes \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m--> 645\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf using all scalar values, you must pass an index\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    647\u001b[0m \u001b[39mif\u001b[39;00m have_series:\n\u001b[0;32m    648\u001b[0m     index \u001b[39m=\u001b[39m union_indexes(indexes)\n",
            "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model(\"crime_lstm_model.h5\")\n",
        "\n",
        "# Load the input data\n",
        "neighbourhood = \"Neighbourhood1\"\n",
        "offence_type = \"OffenceType1\"\n",
        "reportedmonth = 5 # May\n",
        "reporteddayofweek = 2 # Wednesday\n",
        "occurrencehour = 15 # 3 PM\n",
        "\n",
        "# Create a dataframe with the input data\n",
        "input_data = pd.DataFrame({\n",
        "    \"Neighbourhood\": \"University (79)\",\n",
        "    \"offence_type\": \"Assault\",\n",
        "    \"reportedmonth\": \"December\",\n",
        "    \"reporteddayofweek\": \"Friday\",\n",
        "    \"occurrencehour\": 3\n",
        "})\n",
        "\n",
        "# Encode categorical variables\n",
        "cat_cols = ['Neighbourhood', 'offence_type', 'reportedmonth', 'reporteddayofweek']\n",
        "for col in cat_cols:\n",
        "    encoder = LabelEncoder()\n",
        "    input_data[col] = encoder.fit_transform(input_data[col])\n",
        "\n",
        "# Normalize numerical variables\n",
        "num_cols = ['occurrencehour']\n",
        "scaler = MinMaxScaler()\n",
        "input_data[num_cols] = scaler.fit_transform(input_data[num_cols])\n",
        "\n",
        "# Reshape the input data for the LSTM\n",
        "input_data = np.reshape(input_data.values, (input_data.shape[0], 1, input_data.shape[1]))\n",
        "\n",
        "# Make a prediction on the input data\n",
        "predicted_prob = model.predict(input_data)\n",
        "\n",
        "# Print the predicted probability\n",
        "print(\"The probability of a crime occurring in {} at {} on a {} in {} with offence type {} is {:.2f}%\".format(\n",
        "    neighbourhood, occurrencehour, reporteddayofweek, reportedmonth, offence_type, predicted_prob[0][0]*100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"crimelstm.csv\")\n",
        "\n",
        "# Select the relevant columns\n",
        "cols = ['Neighbourhood', 'offence_type', 'reportedmonth', 'reporteddayofweek', 'occurrencehour']\n",
        "data = data[cols]\n",
        "\n",
        "# Encode categorical variables\n",
        "cat_cols = ['Neighbourhood', 'offence_type', 'reportedmonth', 'reporteddayofweek']\n",
        "for col in cat_cols:\n",
        "    encoder = LabelEncoder()\n",
        "    data[col] = encoder.fit_transform(data[col])\n",
        "\n",
        "# Save the encoded classes\n",
        "np.save('Neighbourhood_classes.npy', encoder.classes_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('Neighbourhood_classes.npy', encoder.classes_)\n",
        "np.save('offence_type_classes.npy', encoder.classes_)\n",
        "np.save('month_classes.npy', encoder.classes_)\n",
        "np.save('day_classes.npy', encoder.classes_)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"crimelstm.csv\")\n",
        "\n",
        "# Select the relevant columns\n",
        "cols = ['Neighbourhood', 'offence_type', 'reportedmonth', 'reporteddayofweek', 'occurrencehour']\n",
        "data = data[cols]\n",
        "\n",
        "# Encode categorical variables\n",
        "cat_cols = ['Neighbourhood', 'offence_type', 'reportedmonth', 'reporteddayofweek']\n",
        "for col in cat_cols:\n",
        "    encoder = LabelEncoder()\n",
        "    data[col] = encoder.fit_transform(data[col])\n",
        "\n",
        "# Normalize numerical variables\n",
        "num_cols = ['occurrencehour']\n",
        "scaler = MinMaxScaler()\n",
        "data[num_cols] = scaler.fit_transform(data[num_cols])\n",
        "\n",
        "# Save the maximum values of the scaler object\n",
        "np.save('scaler_max.npy', scaler.data_max_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"crimelstm.csv\")\n",
        "\n",
        "# Select the relevant columns\n",
        "cols = ['Neighbourhood', 'offence_type', 'reportedmonth', 'reporteddayofweek', 'occurrencehour']\n",
        "data = data[cols]\n",
        "\n",
        "# Encode categorical variables\n",
        "cat_cols = ['Neighbourhood', 'offence_type', 'reportedmonth', 'reporteddayofweek']\n",
        "for col in cat_cols:\n",
        "    encoder = LabelEncoder()\n",
        "    data[col] = encoder.fit_transform(data[col])\n",
        "\n",
        "# Normalize numerical variables\n",
        "num_cols = ['occurrencehour']\n",
        "scaler = MinMaxScaler()\n",
        "data[num_cols] = scaler.fit_transform(data[num_cols])\n",
        "\n",
        "# Save the minimum values of the scaler object\n",
        "np.save('scaler_min.npy', scaler.data_min_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "y contains previously unseen labels: 'Broadview North (57)'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\Akanksha Mishra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_encode.py:224\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    225\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\Akanksha Mishra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_encode.py:164\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[1;34m(values, uniques)\u001b[0m\n\u001b[0;32m    163\u001b[0m table \u001b[39m=\u001b[39m _nandict({val: i \u001b[39mfor\u001b[39;00m i, val \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 164\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([table[v] \u001b[39mfor\u001b[39;49;00m v \u001b[39min\u001b[39;49;00m values])\n",
            "File \u001b[1;32mc:\\Users\\Akanksha Mishra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_encode.py:164\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    163\u001b[0m table \u001b[39m=\u001b[39m _nandict({val: i \u001b[39mfor\u001b[39;00m i, val \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 164\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([table[v] \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m values])\n",
            "File \u001b[1;32mc:\\Users\\Akanksha Mishra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_encode.py:158\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnan_value\n\u001b[1;32m--> 158\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'Broadview North (57)'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[28], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m occurrencehour \u001b[39m=\u001b[39m \u001b[39m12\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[39m# Encode the categorical variables\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m Neighbourhood_encoded \u001b[39m=\u001b[39m Neighbourhood_encoder\u001b[39m.\u001b[39;49mtransform([Neighbourhood])\n\u001b[0;32m     31\u001b[0m offence_type_encoded \u001b[39m=\u001b[39m offence_type_encoder\u001b[39m.\u001b[39mtransform([offence_type])\n\u001b[0;32m     32\u001b[0m month_encoded \u001b[39m=\u001b[39m month_encoder\u001b[39m.\u001b[39mtransform([reportedmonth])\n",
            "File \u001b[1;32mc:\\Users\\Akanksha Mishra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\Akanksha Mishra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:139\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mif\u001b[39;00m _num_samples(y) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    137\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([])\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m _encode(y, uniques\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclasses_)\n",
            "File \u001b[1;32mc:\\Users\\Akanksha Mishra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_encode.py:226\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[39mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    225\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 226\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my contains previously unseen labels: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(e)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    227\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    228\u001b[0m     \u001b[39mif\u001b[39;00m check_unknown:\n",
            "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: 'Broadview North (57)'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "# Load the model\n",
        "model = load_model(\"crime_lstm_model.h5\")\n",
        "\n",
        "# Load the label encoders and scaler used for training\n",
        "Neighbourhood_encoder = LabelEncoder()\n",
        "offence_type_encoder = LabelEncoder()\n",
        "month_encoder = LabelEncoder()\n",
        "day_encoder = LabelEncoder()\n",
        "scaler = MinMaxScaler()\n",
        "Neighbourhood_encoder.classes_ = np.load('Neighbourhood_classes.npy', allow_pickle=True)\n",
        "offence_type_encoder.classes_ = np.load('offence_type_classes.npy', allow_pickle=True)\n",
        "month_encoder.classes_ = np.load('month_classes.npy', allow_pickle=True)\n",
        "day_encoder.classes_ = np.load('day_classes.npy', allow_pickle=True)\n",
        "scaler.data_max_ = np.load('scaler_max.npy', allow_pickle=True)\n",
        "scaler.data_min_ = np.load('scaler_min.npy', allow_pickle=True)\n",
        "\n",
        "# Define the input variables\n",
        "Neighbourhood = \"Broadview North (57)\"\n",
        "offence_type = \"Assault\"\n",
        "reportedmonth = \"January\"  # January\n",
        "reporteddayofweek = \"Wednesday\"  # Wednesday\n",
        "occurrencehour = 12\n",
        "\n",
        "# Encode the categorical variables\n",
        "Neighbourhood_encoded = Neighbourhood_encoder.transform([Neighbourhood])\n",
        "offence_type_encoded = offence_type_encoder.transform([offence_type])\n",
        "month_encoded = month_encoder.transform([reportedmonth])\n",
        "day_encoded = day_encoder.transform([reporteddayofweek])\n",
        "\n",
        "# Normalize the numerical variable\n",
        "hour_normalized = scaler.transform([[occurrencehour]])[0][0]\n",
        "\n",
        "# Create a DataFrame with the input variables\n",
        "data = pd.DataFrame({\n",
        "    'Neighbourhood': Neighbourhood_encoded,\n",
        "    'offence_type': offence_type_encoded,\n",
        "    'reportedmonth': month_encoded,\n",
        "    'reporteddayofweek': day_encoded,\n",
        "    'occurrencehour': hour_normalized\n",
        "})\n",
        "\n",
        "# Reshape the input data for the LSTM\n",
        "X = np.reshape(data.values, (1, 1, data.shape[1]))\n",
        "\n",
        "# Make a prediction using the loaded model\n",
        "y_pred = model.predict(X)[0][0]\n",
        "\n",
        "# Print the predicted probability of the crime occurring\n",
        "print(\"The predicted probability of a crime occurring in\", Neighbourhood, \"for an offence type of\", offence_type, \"on a\", day_encoder.classes_[reporteddayofweek], \"in\", month_encoder.classes_[reportedmonth], \"at\", occurrencehour, \"hours is:\", y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
